{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d9cfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================\n",
      " Distributed multiplication 1000x1000\n",
      "===============================\n",
      "\n",
      "--- Splitting matrices into blocks ---\n",
      "Total blocks A: 4\n",
      "Total blocks B: 4\n",
      "Estimated data transferred: 16.00 MB\n",
      "\n",
      "Execution time: 0.05 s\n",
      "CPU usage: 13.0 %\n",
      "Memory usage: 96.9 MB\n",
      "\n",
      "===============================\n",
      " Distributed multiplication 2500x2500\n",
      "===============================\n",
      "\n",
      "--- Splitting matrices into blocks ---\n",
      "Total blocks A: 25\n",
      "Total blocks B: 25\n",
      "Estimated data transferred: 100.00 MB\n",
      "\n",
      "Execution time: 0.71 s\n",
      "CPU usage: 13.3 %\n",
      "Memory usage: 224.8 MB\n",
      "\n",
      "===============================\n",
      " Distributed multiplication 5000x5000\n",
      "===============================\n",
      "\n",
      "--- Splitting matrices into blocks ---\n",
      "Total blocks A: 100\n",
      "Total blocks B: 100\n",
      "Estimated data transferred: 400.00 MB\n",
      "\n",
      "Execution time: 5.22 s\n",
      "CPU usage: 48.0 %\n",
      "Memory usage: 694.7 MB\n",
      "\n",
      "===============================\n",
      " Distributed multiplication 10000x10000\n",
      "===============================\n",
      "\n",
      "--- Splitting matrices into blocks ---\n",
      "Total blocks A: 400\n",
      "Total blocks B: 400\n",
      "Estimated data transferred: 1600.00 MB\n",
      "\n",
      "Execution time: 36.18 s\n",
      "CPU usage: 10.0 %\n",
      "Memory usage: 2561.8 MB\n",
      "\n",
      "Distributed plots saved in folder: plots_distributed/\n",
      "\n",
      "=========== FINAL RESULTS ===========\n",
      "Size: 1000x1000 | Time: 0.05s | Network: 16.00MB | CPU: 13.0% | Mem: 96.9MB | Blocks: 4\n",
      "Size: 2500x2500 | Time: 0.71s | Network: 100.00MB | CPU: 13.3% | Mem: 224.8MB | Blocks: 25\n",
      "Size: 5000x5000 | Time: 5.22s | Network: 400.00MB | CPU: 48.0% | Mem: 694.7MB | Blocks: 100\n",
      "Size: 10000x10000 | Time: 36.18s | Network: 1600.00MB | CPU: 10.0% | Mem: 2561.8MB | Blocks: 400\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "\n",
    "BLOCK_SIZE = 500        \n",
    "DTYPE = np.float64\n",
    "\n",
    "\n",
    "def generate_large_matrix(n):\n",
    "    \"\"\"\n",
    "    Generates a large random matrix.\n",
    "    \"\"\"\n",
    "    return np.random.rand(n, n).astype(DTYPE)\n",
    "\n",
    "\n",
    "def split_into_blocks(matrix, block_size):\n",
    "    \"\"\"\n",
    "    Splits a matrix into square blocks.\n",
    "    \"\"\"\n",
    "    n = matrix.shape[0]\n",
    "    blocks = {}\n",
    "\n",
    "    for i in range(0, n, block_size):\n",
    "        for j in range(0, n, block_size):\n",
    "            blocks[(i // block_size, j // block_size)] = \\\n",
    "                matrix[i:i+block_size, j:j+block_size]\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def map_matrix_A(blocks_A, num_blocks):\n",
    "    mapped = []\n",
    "    for (i, k), block in blocks_A.items():\n",
    "        for j in range(num_blocks):\n",
    "            mapped.append(((i, j), (\"A\", k, block)))\n",
    "    return mapped\n",
    "\n",
    "def map_matrix_B(blocks_B, num_blocks):\n",
    "    mapped = []\n",
    "    for (k, j), block in blocks_B.items():\n",
    "        for i in range(num_blocks):\n",
    "            mapped.append(((i, j), (\"B\", k, block)))\n",
    "    return mapped\n",
    "\n",
    "\n",
    "def reduce_block(key, values):\n",
    "    \"\"\"\n",
    "    Combines partial blocks to compute C_ij.\n",
    "    \"\"\"\n",
    "    A_blocks = {}\n",
    "    B_blocks = {}\n",
    "\n",
    "    for tag, k, block in values:\n",
    "        if tag == \"A\":\n",
    "            A_blocks[k] = block\n",
    "        else:\n",
    "            B_blocks[k] = block\n",
    "\n",
    "    result = None\n",
    "    for k in A_blocks:\n",
    "        if k in B_blocks:\n",
    "            partial = A_blocks[k] @ B_blocks[k]\n",
    "            result = partial if result is None else result + partial\n",
    "\n",
    "    return key, result\n",
    "\n",
    "\n",
    "def distributed_matrix_multiply(A, B):\n",
    "    \"\"\"\n",
    "    Executes distributed matrix multiplication using MapReduce.\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    num_blocks = n // BLOCK_SIZE\n",
    "\n",
    "    print(\"\\n--- Splitting matrices into blocks ---\")\n",
    "    blocks_A = split_into_blocks(A, BLOCK_SIZE)\n",
    "    blocks_B = split_into_blocks(B, BLOCK_SIZE)\n",
    "\n",
    "    # Network overhead estimation\n",
    "    network_bytes = sum(block.nbytes for block in blocks_A.values()) + \\\n",
    "                    sum(block.nbytes for block in blocks_B.values())\n",
    "\n",
    "    print(f\"Total blocks A: {len(blocks_A)}\")\n",
    "    print(f\"Total blocks B: {len(blocks_B)}\")\n",
    "    print(f\"Estimated data transferred: {network_bytes / 1e6:.2f} MB\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    # ---------------- Map ----------------\n",
    "    mapped = map_matrix_A(blocks_A, num_blocks) + \\\n",
    "             map_matrix_B(blocks_B, num_blocks)\n",
    "\n",
    "    # ---------------- Shuffle ----------------\n",
    "    shuffled = defaultdict(list)\n",
    "    for key, value in mapped:\n",
    "        shuffled[key].append(value)\n",
    "\n",
    "    # ---------------- Reduce ----------------\n",
    "    reduced_blocks = {}\n",
    "    for key, values in shuffled.items():\n",
    "        reduced_blocks[key] = reduce_block(key, values)[1]\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "    cpu_usage = psutil.cpu_percent(interval=0.1)\n",
    "    memory_usage = psutil.Process().memory_info().rss / (1024**2)\n",
    "\n",
    "    print(f\"\\nExecution time: {execution_time:.2f} s\")\n",
    "    print(f\"CPU usage: {cpu_usage:.1f} %\")\n",
    "    print(f\"Memory usage: {memory_usage:.1f} MB\")\n",
    "\n",
    "    return reduced_blocks, execution_time, network_bytes, cpu_usage, memory_usage\n",
    "\n",
    "\n",
    "def run_experiments(matrix_sizes):\n",
    "    results = []\n",
    "\n",
    "    for n in matrix_sizes:\n",
    "        print(f\"\\n===============================\")\n",
    "        print(f\" Distributed multiplication {n}x{n}\")\n",
    "        print(f\"===============================\")\n",
    "\n",
    "        A = generate_large_matrix(n)\n",
    "        B = generate_large_matrix(n)\n",
    "\n",
    "        blocks, t, net, cpu, mem = distributed_matrix_multiply(A, B)\n",
    "\n",
    "        results.append({\n",
    "            \"size\": n,\n",
    "            \"time\": t,\n",
    "            \"network_MB\": net / 1e6,\n",
    "            \"cpu\": cpu,\n",
    "            \"memory\": mem,\n",
    "            \"blocks\": len(blocks)\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "def plot_distributed_results(results):\n",
    "\n",
    "    os.makedirs(\"plots_distributed\", exist_ok=True)\n",
    "\n",
    "    sizes = [r[\"size\"] for r in results]\n",
    "    times = [r[\"time\"] for r in results]\n",
    "    network = [r[\"network_MB\"] for r in results]\n",
    "    memory = [r[\"memory\"] for r in results]\n",
    "    cpu = [r[\"cpu\"] for r in results]\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Execution Time\n",
    "    # ------------------------------------------------\n",
    "    plt.figure()\n",
    "    plt.plot(sizes, times, marker=\"o\")\n",
    "    plt.xlabel(\"Matrix size (n)\")\n",
    "    plt.ylabel(\"Execution time (s)\")\n",
    "    plt.title(\"Scalability of Distributed Matrix Multiplication\")\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots_distributed/time_vs_size.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Network Overhead\n",
    "    # ------------------------------------------------\n",
    "    plt.figure()\n",
    "    plt.plot(sizes, network, marker=\"o\")\n",
    "    plt.xlabel(\"Matrix size (n)\")\n",
    "    plt.ylabel(\"Data transferred (MB)\")\n",
    "    plt.title(\"Network Overhead\")\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots_distributed/network_vs_size.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Memory Usage\n",
    "    # ------------------------------------------------\n",
    "    plt.figure()\n",
    "    plt.plot(sizes, memory, marker=\"o\")\n",
    "    plt.xlabel(\"Matrix size (n)\")\n",
    "    plt.ylabel(\"Memory usage (MB)\")\n",
    "    plt.title(\"Memory Consumption\")\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots_distributed/memory_vs_size.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # CPU Usage\n",
    "    # ------------------------------------------------\n",
    "    plt.figure()\n",
    "    plt.plot(sizes, cpu, marker=\"o\")\n",
    "    plt.xlabel(\"Matrix size (n)\")\n",
    "    plt.ylabel(\"CPU usage (%)\")\n",
    "    plt.title(\"CPU Utilization\")\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots_distributed/cpu_vs_size.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Log-Log Plot (Very Important)\n",
    "    # ------------------------------------------------\n",
    "    plt.figure()\n",
    "    plt.loglog(sizes, times, marker=\"o\")\n",
    "    plt.xlabel(\"Matrix size (log scale)\")\n",
    "    plt.ylabel(\"Execution time (log scale)\")\n",
    "    plt.title(\"Log-Log Scalability Plot\")\n",
    "    plt.grid(True, which=\"both\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots_distributed/loglog_time.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"\\nDistributed plots saved in folder: plots_distributed/\")\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    matrix_sizes = [1000, 2500, 5000, 10000]\n",
    "\n",
    "    results = run_experiments(matrix_sizes)\n",
    "    plot_distributed_results(results)\n",
    "\n",
    "    print(\"\\n=========== FINAL RESULTS ===========\")\n",
    "    for r in results:\n",
    "        print(f\"Size: {r['size']}x{r['size']} | \"\n",
    "              f\"Time: {r['time']:.2f}s | \"\n",
    "              f\"Network: {r['network_MB']:.2f}MB | \"\n",
    "              f\"CPU: {r['cpu']:.1f}% | \"\n",
    "              f\"Mem: {r['memory']:.1f}MB | \"\n",
    "              f\"Blocks: {r['blocks']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
